{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b18a5a",
   "metadata": {},
   "source": [
    "<h1>Introduction to classification</h1>\n",
    "\n",
    "In this notebook we will be using the wine quality dataset (available at [kaggle](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset)) to explore how machine learning can be used to infer the quality of a wine based on its attributes.\n",
    "\n",
    "So, first let us explore our dataset using pandas and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the holy trinity of data science.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# getting seaborn online to give our graphics a kick.\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705aaaea",
   "metadata": {},
   "source": [
    "<h1>Summary</h1>\n",
    "\n",
    "Before we start let us....kind of jump to the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re loading the dataset.\n",
    "wine_df = pd.read_csv(\"Datasets\\\\WineQT.csv\")\n",
    "\n",
    "# Separating independent and dependent variables.\n",
    "X = wine_df.drop(['quality','Id'], axis=1)\n",
    "Y = wine_df['quality']\n",
    "\n",
    "# Splitting.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,\n",
    "                                                    Y,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=Y)\n",
    "\n",
    "# Creating the classifier object.\n",
    "RFR = RandomForestClassifier(n_estimators=10,\n",
    "                             max_depth=50, \n",
    "                             random_state=42)\n",
    "\n",
    "# Fitting the train dataset.\n",
    "RFR.fit(X_train,Y_train)\n",
    "\n",
    "# Creating the predictions.\n",
    "Y_pred = RFR.predict(X_test)\n",
    "\n",
    "# Calculating error\n",
    "print(mean_absolute_error(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782c72a",
   "metadata": {},
   "source": [
    "<h1>Now we start the lecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset.\n",
    "wine_df = pd.read_csv(\"WineQT.csv\")\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54240fbc",
   "metadata": {},
   "source": [
    "Question: in the context of our problem, what are the independent variables and what is the dependent variable? (or, what is even all of this?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e9a06",
   "metadata": {},
   "source": [
    "Exercise: how could you check which variables seem better correlated with the independent variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e80be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75537179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fb3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da502e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scattering\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14,4))\n",
    "\n",
    "for xcol, ax in zip(['fixed acidity', 'volatile acidity', 'residual sugar'], axes):\n",
    "    wine_df.plot(kind='scatter', x=xcol, y='quality', ax=ax, alpha=0.5, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc161a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scattering\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14,4))\n",
    "\n",
    "for xcol, ax in zip(['fixed acidity', 'volatile acidity', 'alcohol'], axes):\n",
    "    wine_df.plot(kind='scatter', x=xcol, y='quality', ax=ax, alpha=0.5, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c43bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = wine_df.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d13871",
   "metadata": {},
   "source": [
    "Exercise: What would you consider a wine with high acidity content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c517387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23903934",
   "metadata": {},
   "source": [
    "Exercise: How many rows of missing data do we have? What should we do about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca92b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc65f192",
   "metadata": {},
   "source": [
    "Exercise: are there any columns that we can assume are irrelevant for this exercise? are there any....potentially dangerous columns out there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = wine_df.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84dd100",
   "metadata": {},
   "source": [
    "Exercise: Check if you have [scikit-learn](https://scikit-learn.org/stable/install.html) installed and install it if you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a2179",
   "metadata": {},
   "source": [
    "Now we will manually encode the quality column to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c452693",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.quality.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WineSnob(x):\n",
    "    if x<=4:\n",
    "        return('Nope')\n",
    "    elif x<7:\n",
    "        return('Ok')\n",
    "    elif x>=7:\n",
    "        return('More')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.quality.apply(lambda x: WineSnob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff9794",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['quality_str'] = wine_df.quality.apply(lambda x: WineSnob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['quality_str'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad61a51",
   "metadata": {},
   "source": [
    "Question: how to we handle non-numerical variables? What steps can we take to ensure the machine can make sense of it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022bcb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be64fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit_transform(wine_df['quality_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['quality_enc'] = le.fit_transform(wine_df['quality_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92602997",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['quality_str'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb99a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['quality_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f677e724",
   "metadata": {},
   "source": [
    "Question: in this specific case was all of this largely unecessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9748244",
   "metadata": {},
   "source": [
    "Now how can we use this data to make predictions? What are the steps involved?\n",
    "\n",
    "<h1>Splitting the dataset</h1>\n",
    "\n",
    "We will first split the dataset into a training set and a test set. But why would we do this on the first place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that I will slightly change how I import libraries for now on to be more specific.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cae872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the train and test.\n",
    "train, test = train_test_split(wine_df, random_state=42) #train_size=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13600dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c64def",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)/len(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92549ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dcd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb3527",
   "metadata": {},
   "source": [
    "Exercise: Check the train_test_split [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) and try to figure out how to change the proportion of train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test = train_test_split(wine_df, train_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5837d",
   "metadata": {},
   "source": [
    "Question: what proportion of train and test set should we use? Would it make a difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e9912",
   "metadata": {},
   "source": [
    "Question: if you and your colleagues run the same line of code to separate the datasets, should you always find the same results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915de481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2292b1a9",
   "metadata": {},
   "source": [
    "After my incredibly interesting and engaging monologue about randomness we will separate our dependent and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['quality','quality_str','quality_enc'], axis=1)\n",
    "Y_train = train['quality_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0036d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['quality','quality_str','quality_enc'], axis=1)\n",
    "Y_test = test['quality_enc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba14df",
   "metadata": {},
   "source": [
    "<h1>Feature scalling</h1>\n",
    "\n",
    "It is a common practice in machine learning to scale features. We will check how to do this process on the next few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6326f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde827d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e646334",
   "metadata": {},
   "source": [
    "Exercise: print the first 5 rows of one of the objects defined above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d99e92",
   "metadata": {},
   "source": [
    "Should we feature scale Y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eda1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = StandardScaler().fit_transform(Y_train)\n",
    "Y_test = StandardScaler().fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cca482",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nope = Y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251360a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nope.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac30f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nope = StandardScaler().fit_transform(Y_train_nope.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261cb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfac2a1",
   "metadata": {},
   "source": [
    "But really....what do we stand to gain doing all this? Will the model still run later on if you don't apply feature scalling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff91b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset.\n",
    "wine_df = pd.read_csv(\"WineQT.csv\")\n",
    "\n",
    "# Separating the train and test.\n",
    "train, test = train_test_split(wine_df, random_state=42)\n",
    "\n",
    "X_train = train.drop(['quality','Id'], axis=1)\n",
    "Y_train = train['quality']\n",
    "X_test = test.drop(['quality','Id'], axis=1)\n",
    "Y_test = test['quality']\n",
    "\n",
    "# Scalling.\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8dde8f",
   "metadata": {},
   "source": [
    "<h1>The decision tree classifier</h1>\n",
    "In the next few blocks we will be exploring the use of \n",
    "\n",
    "[decision trees](https://scikit-learn.org/stable/modules/tree.html) to classify our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd74fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model.\n",
    "DTR = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# fit and batch of predictions.\n",
    "DTR.fit(X_train,Y_train)\n",
    "Y_pred = DTR.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897b661",
   "metadata": {},
   "source": [
    "Exercise: how can you visually check how good the performance was?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bd914",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db071eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(14,6))\n",
    "x_axis = np.arange(0,len(Y_pred))\n",
    "\n",
    "ax.scatter(x_axis,Y_test, s=10, label='Test')\n",
    "ax.scatter(x_axis,Y_pred, s=25, label='Pred', alpha=0.25)\n",
    "\n",
    "ax.set_title(f'The wine snob classifier!')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c063f2b",
   "metadata": {},
   "source": [
    "<h1>Measuring accuracy</h1>\n",
    "There are many metrics that can be used to measure the accuracy of a model. \n",
    "Over the next few blocks we will see how to use both the\n",
    "\n",
    "[mean absolut error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) and [mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_mae = mean_absolute_error(Y_test,Y_pred)\n",
    "ys_mse = mean_squared_error(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE {ys_mae}, MSE {ys_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7638a",
   "metadata": {},
   "source": [
    "Exercise: check the [DTC] documentation and run the model for a different depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c44ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model.\n",
    "DTR = DecisionTreeClassifier(max_depth = 15, random_state=42)\n",
    "\n",
    "# Systolic fit and batch of predictions.\n",
    "DTR.fit(X_train,Y_train)\n",
    "Y_pred = DTR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_mae = mean_absolute_error(Y_test,Y_pred)\n",
    "ys_mse = mean_squared_error(Y_test,Y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(14,6))\n",
    "x_axis = np.arange(0,len(Y_pred))\n",
    "\n",
    "ax.scatter(x_axis,Y_test, s=10, label='Test')\n",
    "ax.scatter(x_axis,Y_pred, s=25, label='Pred', alpha=0.25)\n",
    "\n",
    "ax.set_title(f\"MAE {ys_mae:.2f}, MSE {ys_mse:.2f}\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28470a4",
   "metadata": {},
   "source": [
    "Question: If the results depend on the parameters we set, how could you determine the optimum number of parameters? Exercise: do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(1,100):\n",
    "    # Initializing the model.\n",
    "    DTR = DecisionTreeClassifier(max_depth=i, \n",
    "                                 random_state=42)\n",
    "\n",
    "    # Systolic fit and batch of predictions.\n",
    "    DTR.fit(X_train,Y_train)\n",
    "    Y_pred = DTR.predict(X_test)\n",
    "\n",
    "    ys_mae = mean_absolute_error(Y_test,Y_pred)\n",
    "\n",
    "    results.append(ys_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4752c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c513b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c2d034",
   "metadata": {},
   "source": [
    "<h1>The randon forest regressor</h1>\n",
    "The implementation of the random forest classifier is quite similar to what has previously seen although the rationale of how they work bear some significant differences. Details can be found in the \n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifier object.\n",
    "RFR = RandomForestClassifier(n_estimators=10,\n",
    "                             max_depth=50, \n",
    "                             random_state=42)\n",
    "\n",
    "# Fitting the train dataset.\n",
    "RFR.fit(X_train,Y_train)\n",
    "\n",
    "# Creating the predictions.\n",
    "Y_pred = RFR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_mae = mean_absolute_error(Y_test,Y_pred)\n",
    "ys_mse = mean_squared_error(Y_test,Y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(14,6))\n",
    "x_axis = np.arange(0,len(Y_pred))\n",
    "\n",
    "ax.scatter(x_axis,Y_test, s=10, label='Test')\n",
    "ax.scatter(x_axis,Y_pred, s=25, label='Pred', alpha=0.25)\n",
    "\n",
    "ax.set_title(f\"MAE {ys_mae:.2f}, MSE {ys_mse:.2f}\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4283bde",
   "metadata": {},
   "source": [
    "Exercise: The accuracy obtained is currently dreadful. Improve on that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(1,100):\n",
    "    # Creating the classifier object.\n",
    "    RFR = RandomForestClassifier(n_estimators=i,\n",
    "                                 max_depth=10, \n",
    "                                 random_state=42)\n",
    "\n",
    "    # Fitting the train dataset.\n",
    "    RFR.fit(X_train,Y_train)\n",
    "\n",
    "    # Creating the predictions.\n",
    "    Y_pred = RFR.predict(X_test)\n",
    "\n",
    "    # Calculate error\n",
    "    ys_mae = mean_absolute_error(Y_test,Y_pred)\n",
    "    \n",
    "    # Appending to the list.\n",
    "    results.append(ys_mae)\n",
    "    \n",
    "print(min(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2117696",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_min = min(range(len(results)), key=results.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779cc58a",
   "metadata": {},
   "source": [
    "<h1>Support Vector Machines</h1>\n",
    "\n",
    "The last technique we will see today are the Support Vector Machines (or SVMs for short).\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/svm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b55342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model.\n",
    "SVC = svm.SVC(kernel='linear', degree=1)\n",
    "\n",
    "# Fit and batch of predictions.\n",
    "SVC.fit(X_train,Y_train)\n",
    "\n",
    "# Creating the predictions.\n",
    "Y_pred = SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0371c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_mae = mean_absolute_error(Y_test,Y_pred)\n",
    "ys_mse = mean_squared_error(Y_test,Y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(14,6))\n",
    "x_axis = np.arange(0,len(Y_pred))\n",
    "\n",
    "ax.scatter(x_axis,Y_test, s=10, label='Test')\n",
    "ax.scatter(x_axis,Y_pred, s=25, label='Pred', alpha=0.25)\n",
    "\n",
    "ax.set_title(f\"MAE {ys_mae:.2f}, MSE {ys_mse:.2f}\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc280b2",
   "metadata": {},
   "source": [
    "Exercise: improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db895d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eb05a48",
   "metadata": {},
   "source": [
    "<h1>Pipelining</h1>\n",
    "\n",
    "Hint: check this [post](https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a37a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4229199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re loading the dataset.\n",
    "wine_df = pd.read_csv(\"WineQT.csv\")\n",
    "wine_df.head()\n",
    "\n",
    "# Separating independent and dependent variables.\n",
    "X = wine_df.drop(['quality','Id'], axis=1)\n",
    "Y = wine_df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acadedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    Y,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e308767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pipeline.\n",
    "steps = [('scaler', StandardScaler()), ('SVM', svm.SVC())]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteres = {'SVM__C':[0.001,0.1,10,100,10e5], 'SVM__gamma':[0.1,0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the gridsearch.\n",
    "grid = GridSearchCV(pipeline, \n",
    "                    param_grid=parameteres, \n",
    "                    cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f83831",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print(\"score = %3.2f\" %(grid.score(X_test,y_test)))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244fda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e43b7ea",
   "metadata": {},
   "source": [
    "Exercise: re-run the model without applying feature scalling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a46137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
